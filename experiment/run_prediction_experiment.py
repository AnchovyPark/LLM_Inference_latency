"""
LLM ì§€ì—°ì‹œê°„ ì˜ˆì¸¡ ì‹¤í—˜ ì‹¤í–‰ê¸°

ì‹œë‚˜ë¦¬ì˜¤ CSVë¥¼ ì½ì–´ì„œ ìš°ë¦¬ ì˜ˆì¸¡ê¸°ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•˜ê³  
ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import csv
import os
import sys
import pandas as pd
from datetime import datetime
from typing import List, Dict

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ì˜ˆì¸¡ê¸° import
sys.path.append('/Users/anchovy-mac/Desktop/calculating')
from llm_latency_predictor import LLMLatencyPredictor


def load_scenarios(csv_file: str) -> List[Dict]:
    """ì‹œë‚˜ë¦¬ì˜¤ CSV íŒŒì¼ ë¡œë“œ"""
    
    filepath = f'/Users/anchovy-mac/Desktop/calculating/experiment/{csv_file}'
    scenarios = []
    
    with open(filepath, 'r', encoding='utf-8') as file:
        reader = csv.DictReader(file)
        for row in reader:
            # ìˆ«ì í•„ë“œë“¤ì„ intë¡œ ë³€í™˜
            row['scenario_id'] = int(row['scenario_id'])
            row['input_length'] = int(row['input_length'])
            row['output_length'] = int(row['output_length'])
            row['batch_size'] = int(row['batch_size'])
            scenarios.append(row)
    
    return scenarios


def run_predictions(scenarios: List[Dict], predictor: LLMLatencyPredictor) -> List[Dict]:
    """ì‹œë‚˜ë¦¬ì˜¤ë“¤ì— ëŒ€í•´ ì˜ˆì¸¡ ì‹¤í–‰"""
    
    results = []
    total_scenarios = len(scenarios)
    
    print(f"ğŸ”® {total_scenarios}ê°œ ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•´ ì˜ˆì¸¡ ì‹¤í–‰ ì¤‘...")
    print("-" * 60)
    
    for i, scenario in enumerate(scenarios, 1):
        try:
            # ì˜ˆì¸¡ ì‹¤í–‰
            result = predictor.predict_latency(
                model_name=scenario['model'],
                gpu_name=scenario['gpu'], 
                input_length=scenario['input_length'],
                output_length=scenario['output_length'],
                batch_size=scenario['batch_size']
            )
            
            # ê²°ê³¼ ì €ì¥
            prediction_result = {
                'scenario_id': scenario['scenario_id'],
                'gpu': scenario['gpu'],
                'model': scenario['model'],
                'input_length': scenario['input_length'],
                'output_length': scenario['output_length'],
                'batch_size': scenario['batch_size'],
                'use_case': scenario['use_case'],
                
                # ì˜ˆì¸¡ ê²°ê³¼ë“¤
                'predicted_prefill_ms': round(result.prefill_ms, 2),
                'predicted_decode_per_token_ms': round(result.decode_per_token_ms, 4),
                'predicted_total_decode_ms': round(result.total_decode_ms, 2),
                'predicted_total_ms': round(result.total_ms, 2),
                'predicted_throughput_tokens_per_sec': round(scenario['output_length'] / (result.total_ms / 1000), 2),
                
                # ì„¸ë¶€ ë¶„ì„
                'predicted_linear_ms': round(result.linear_ms, 2),
                'predicted_attention_ms': round(result.attention_ms, 2),
                'predicted_mlp_ms': round(result.mlp_ms, 2),
                'predicted_norm_ms': round(result.norm_ms, 2),
                'predicted_other_ms': round(result.other_ms, 2),
                'predicted_memory_transfer_ms': round(result.memory_transfer_ms, 2),
                'predicted_compute_ms': round(result.compute_ms, 2),
                
                'prediction_timestamp': datetime.now().isoformat()
            }
            
            results.append(prediction_result)
            
            # ì§„í–‰ìƒí™© ì¶œë ¥
            if i % 10 == 0 or i == total_scenarios:
                print(f"âœ… {i}/{total_scenarios} ì™„ë£Œ ({i/total_scenarios*100:.1f}%)")
                
        except Exception as e:
            print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ {scenario['scenario_id']} ì‹¤íŒ¨: {e}")
            
            # ì‹¤íŒ¨í•œ ê²½ìš°ë„ ê¸°ë¡
            error_result = {
                'scenario_id': scenario['scenario_id'],
                'gpu': scenario['gpu'],
                'model': scenario['model'],
                'input_length': scenario['input_length'],
                'output_length': scenario['output_length'],
                'batch_size': scenario['batch_size'],
                'use_case': scenario['use_case'],
                'error': str(e),
                'prediction_timestamp': datetime.now().isoformat()
            }
            results.append(error_result)
    
    return results


def save_predictions_to_csv(predictions: List[Dict], filename: str):
    """ì˜ˆì¸¡ ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
    
    filepath = f'/Users/anchovy-mac/Desktop/calculating/experiment/{filename}'
    
    if not predictions:
        print("âŒ ì €ì¥í•  ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # í•„ë“œëª… ì •ì˜ (ì—ëŸ¬ê°€ ìˆëŠ” ê²½ìš°ì™€ ì—†ëŠ” ê²½ìš° ëª¨ë‘ ê³ ë ¤)
    fieldnames = list(predictions[0].keys())
    
    with open(filepath, 'w', newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(predictions)
    
    print(f"ğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ê°€ {filepath}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤")


def analyze_predictions(predictions: List[Dict]):
    """ì˜ˆì¸¡ ê²°ê³¼ ë¶„ì„"""
    
    # ì„±ê³µ/ì‹¤íŒ¨ í†µê³„
    successful = [p for p in predictions if 'error' not in p]
    failed = [p for p in predictions if 'error' in p]
    
    print(f"\nğŸ“ˆ ì˜ˆì¸¡ ì‹¤í–‰ ê²°ê³¼ ë¶„ì„:")
    print("-" * 40)
    print(f"âœ… ì„±ê³µ: {len(successful)}ê°œ")
    print(f"âŒ ì‹¤íŒ¨: {len(failed)}ê°œ")
    print(f"ğŸ“Š ì„±ê³µë¥ : {len(successful)/len(predictions)*100:.1f}%")
    
    if successful:
        df = pd.DataFrame(successful)
        
        print(f"\nâš¡ ì§€ì—°ì‹œê°„ í†µê³„ (ms):")
        print(f"  â€¢ í‰ê·  ì´ ì§€ì—°ì‹œê°„: {df['predicted_total_ms'].mean():.1f} ms")
        print(f"  â€¢ ìµœì†Œ ì´ ì§€ì—°ì‹œê°„: {df['predicted_total_ms'].min():.1f} ms")
        print(f"  â€¢ ìµœëŒ€ ì´ ì§€ì—°ì‹œê°„: {df['predicted_total_ms'].max():.1f} ms")
        
        print(f"\nğŸš€ ì²˜ë¦¬ëŸ‰ í†µê³„ (tokens/sec):")
        print(f"  â€¢ í‰ê·  ì²˜ë¦¬ëŸ‰: {df['predicted_throughput_tokens_per_sec'].mean():.1f} tokens/sec")
        print(f"  â€¢ ìµœì†Œ ì²˜ë¦¬ëŸ‰: {df['predicted_throughput_tokens_per_sec'].min():.1f} tokens/sec")
        print(f"  â€¢ ìµœëŒ€ ì²˜ë¦¬ëŸ‰: {df['predicted_throughput_tokens_per_sec'].max():.1f} tokens/sec")
        
        # GPUë³„ í‰ê·  ì§€ì—°ì‹œê°„
        print(f"\nğŸ–¥ï¸  GPUë³„ í‰ê·  ì´ ì§€ì—°ì‹œê°„:")
        gpu_latency = df.groupby('gpu')['predicted_total_ms'].mean().sort_values()
        for gpu, latency in gpu_latency.items():
            print(f"  â€¢ {gpu}: {latency:.1f} ms")
    
    if failed:
        print(f"\nâŒ ì‹¤íŒ¨í•œ ì‹œë‚˜ë¦¬ì˜¤ë“¤:")
        for fail in failed[:5]:  # ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ
            print(f"  â€¢ {fail['gpu']}-{fail['model']}: {fail.get('error', 'Unknown error')}")


def main():
    """ë©”ì¸ ì‹¤í—˜ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸ§ª LLM ì§€ì—°ì‹œê°„ ì˜ˆì¸¡ ì‹¤í—˜")
    print("=" * 50)
    
    # ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
    print("ğŸ”§ ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” ì¤‘...")
    predictor = LLMLatencyPredictor()
    
    # ëª…ë ¹í–‰ ì¸ìˆ˜ í™•ì¸
    import sys
    if len(sys.argv) > 1:
        # íŠ¹ì • ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼ ì²˜ë¦¬
        scenario_file = sys.argv[1]
        if not scenario_file.endswith('.csv'):
            scenario_file += '.csv'
        
        output_file = scenario_file.replace('.csv', '_predictions.csv')
        scenario_files = [(scenario_file, output_file)]
    else:
        # ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼ë“¤
        scenario_files = [
            ('balanced_scenarios.csv', 'balanced_predictions.csv'),
            ('random_scenarios.csv', 'random_predictions.csv')
        ]
    
    for scenario_file, output_file in scenario_files:
        print(f"\nğŸ“‹ {scenario_file} ì²˜ë¦¬ ì¤‘...")
        
        try:
            # ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œ
            scenarios = load_scenarios(scenario_file)
            print(f"ğŸ“– {len(scenarios)}ê°œ ì‹œë‚˜ë¦¬ì˜¤ ë¡œë“œë¨")
            
            # ì˜ˆì¸¡ ì‹¤í–‰
            predictions = run_predictions(scenarios, predictor)
            
            # ê²°ê³¼ ì €ì¥
            save_predictions_to_csv(predictions, output_file)
            
            # ë¶„ì„
            analyze_predictions(predictions)
            
        except FileNotFoundError:
            print(f"âš ï¸  {scenario_file}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì„ í™•ì¸í•˜ì„¸ìš”.")
        except Exception as e:
            print(f"âŒ {scenario_file} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    print(f"\nğŸ‰ ì‹¤í—˜ ì™„ë£Œ!")


if __name__ == "__main__":
    main()